= ProximaDB Developer Guide
:toc:
:toc-placement: preamble
:icons: font
:source-highlighter: highlight.js
:imagesdir: diagrams/images

== Introduction

This developer guide provides comprehensive information for developers working on ProximaDB, including architecture details, development setup, coding conventions, and contribution guidelines for the multi-disk assignment service architecture.

== 1. Development Environment Setup

=== 1.1 Prerequisites

==== System Requirements
* **Rust**: 1.70.0 or later with cargo
* **Git**: For version control
* **Docker**: For containerized development (optional)
* **Java**: For PlantUML diagram generation (optional)

==== Development Tools
[source,bash]
----
# Install Rust via rustup
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Install required components
rustup component add clippy rustfmt

# Install development dependencies
cargo install cargo-watch cargo-audit cargo-outdated
----

=== 1.2 Repository Setup

[source,bash]
----
# Clone the repository
git clone https://github.com/proximadb/proximadb.git
cd proximadb

# Install dependencies
cargo build

# Run tests
cargo test

# Start development server with multi-disk config
cargo run --bin proximadb-server -- --config config.toml
----

=== 1.3 IDE Configuration

==== VS Code Setup
Recommended extensions:
* `rust-analyzer`: Rust language support
* `CodeLLDB`: Debugging support
* `Better TOML`: Configuration file support

==== IntelliJ IDEA Setup
* Install Rust plugin
* Configure Cargo project structure
* Set up debugging configurations

== 2. Multi-Disk Architecture Deep Dive

=== 2.1 Assignment Service Architecture

image::Assignment Service Flow.png[Assignment Service Flow, align="center"]

The assignment service is the core of ProximaDB's multi-disk architecture:

==== Key Components

[source,rust]
----
// Core trait for assignment operations
#[async_trait]
pub trait AssignmentService: Send + Sync {
    async fn assign_storage_url(
        &self,
        collection_id: &CollectionId,
        config: &StorageAssignmentConfig,
    ) -> Result<StorageAssignmentResult>;
    
    async fn get_assignment(
        &self,
        collection_id: &CollectionId,
        component_type: StorageComponentType,
    ) -> Option<StorageAssignmentResult>;
    
    async fn record_assignment(
        &self,
        collection_id: &CollectionId,
        component_type: StorageComponentType,
        assignment: StorageAssignmentResult,
    ) -> Result<()>;
    
    async fn get_all_assignments(
        &self,
        component_type: StorageComponentType,
    ) -> HashMap<CollectionId, StorageAssignmentResult>;
    
    async fn get_assignment_stats(&self) -> Result<serde_json::Value>;
}

// Round-robin implementation
pub struct RoundRobinAssignmentService {
    assignments: Arc<RwLock<HashMap<StorageComponentType, HashMap<CollectionId, StorageAssignmentResult>>>>,
    round_robin_counters: Arc<RwLock<HashMap<StorageComponentType, usize>>>,
}
----

==== Implementation Details

===== Assignment Algorithm
[source,rust]
----
impl RoundRobinAssignmentService {
    async fn get_next_round_robin_index(
        &self,
        component_type: StorageComponentType,
        storage_urls: &[String],
    ) -> Result<usize> {
        let mut counters = self.round_robin_counters.write().await;
        let counter = counters.entry(component_type).or_insert(0);
        let index = *counter % storage_urls.len();
        *counter = (*counter + 1) % storage_urls.len();
        Ok(index)
    }
    
    async fn assign_with_affinity(
        &self,
        collection_id: &CollectionId,
        storage_urls: &[String],
    ) -> Result<usize> {
        let hash = self.hash_collection_id(collection_id);
        Ok(hash % storage_urls.len())
    }
    
    fn hash_collection_id(&self, collection_id: &CollectionId) -> usize {
        let mut hasher = DefaultHasher::new();
        collection_id.hash(&mut hasher);
        hasher.finish() as usize
    }
}
----

=== 2.2 WAL Strategy Pattern

image::WAL Strategy Pattern.png[WAL Strategy Pattern, align="center"]

The WAL uses a strategy pattern for pluggable serialization with integrated assignment service:

==== Base Strategy Trait
[source,rust]
----
#[async_trait]
pub trait WalStrategy: Send + Sync {
    fn strategy_name(&self) -> &'static str;
    fn get_assignment_service(&self) -> &Arc<dyn AssignmentService>;
    
    // Common assignment logic implemented in base trait
    async fn select_wal_url_for_collection(
        &self,
        collection_id: &str,
        config: &WalConfig,
    ) -> Result<String> {
        // Check existing assignment first
        if let Some(assignment) = self.get_assignment_service()
            .get_assignment(
                &CollectionId::from(collection_id.to_string()),
                StorageComponentType::Wal,
            )
            .await
        {
            return Ok(assignment.storage_url);
        }
        
        // Create new assignment if none exists
        let assignment_config = StorageAssignmentConfig {
            storage_urls: config.wal_urls.clone(),
            component_type: StorageComponentType::Wal,
            collection_affinity: config.collection_affinity,
        };
        
        let assignment = self.get_assignment_service()
            .assign_storage_url(
                &CollectionId::from(collection_id.to_string()),
                &assignment_config,
            )
            .await?;
            
        Ok(assignment.storage_url)
    }
    
    async fn discover_existing_assignments(&self, config: &WalConfig) -> Result<()> {
        // Discovery implementation for startup recovery
    }
}
----

==== Strategy Implementations
[source,rust]
----
// Avro strategy for cross-language compatibility
pub struct AvroWalStrategy {
    config: Option<WalConfig>,
    filesystem: Option<Arc<FilesystemFactory>>,
    memory_table: Option<WalMemTable>,
    disk_manager: Option<WalDiskManager>,
    storage_engine: Option<Arc<UnifiedStorageEngine>>,
    assignment_service: Arc<dyn AssignmentService>,
}

#[async_trait]
impl WalStrategy for AvroWalStrategy {
    fn strategy_name(&self) -> &'static str { "Avro" }
    
    fn get_assignment_service(&self) -> &Arc<dyn AssignmentService> {
        &self.assignment_service
    }
    
    async fn serialize_entries(&self, entries: &[WalEntry]) -> Result<Vec<u8>> {
        let schema = avro_rs::Schema::parse_str(WAL_AVRO_SCHEMA)?;
        let mut writer = avro_rs::Writer::new(&schema, Vec::new());
        
        for entry in entries {
            writer.append_ser(entry)?;
        }
        
        Ok(writer.into_inner()?)
    }
}

// Bincode strategy for Rust performance
pub struct BincodeWalStrategy {
    config: Option<WalConfig>,
    filesystem: Option<Arc<FilesystemFactory>>,
    memory_table: Option<WalMemTable>,
    disk_manager: Option<WalDiskManager>,
    storage_engine: Option<Arc<UnifiedStorageEngine>>,
    assignment_service: Arc<dyn AssignmentService>,
}

#[async_trait]  
impl WalStrategy for BincodeWalStrategy {
    fn strategy_name(&self) -> &'static str { "Bincode" }
    
    fn get_assignment_service(&self) -> &Arc<dyn AssignmentService> {
        &self.assignment_service
    }
    
    async fn serialize_entries(&self, entries: &[WalEntry]) -> Result<Vec<u8>> {
        bincode::serialize(entries).map_err(|e| ProximaDBError::Internal(e.to_string()))
    }
}
----

=== 2.3 Data Flow Architecture

image::Data Flow and Persistence.png[Data Flow and Persistence, align="center"]

Understanding the complete data flow from API to multi-disk persistence:

==== Write Path Implementation
[source,rust]
----
pub async fn handle_vector_insert_pipeline(
    &self,
    collection_id: &str,
    vectors: Vec<VectorInsertRequest>,
) -> Result<InsertResult> {
    // 1. Validate collection exists
    let collection = self.collection_service
        .get_collection_by_name_or_uuid(collection_id)
        .await?
        .ok_or(ProximaDBError::NotFound(format!("Collection {}", collection_id)))?;
    
    // 2. Get or create assignment for this collection
    let assignment = match self.assignment_service
        .get_assignment(
            &CollectionId::from(collection_id.to_string()), 
            StorageComponentType::Wal
        )
        .await 
    {
        Some(assignment) => assignment,
        None => {
            // Create new assignment using round-robin
            let assignment_config = StorageAssignmentConfig {
                storage_urls: self.config.storage.wal_config.wal_urls.clone(),
                component_type: StorageComponentType::Wal,
                collection_affinity: self.config.storage.wal_config.collection_affinity,
            };
            
            self.assignment_service
                .assign_storage_url(
                    &CollectionId::from(collection_id.to_string()),
                    &assignment_config,
                )
                .await?
        }
    };
    
    // 3. Convert to WAL entries
    let wal_entries: Vec<WalEntry> = vectors.into_iter()
        .map(|v| WalEntry {
            vector_id: v.id,
            vector: v.vector,
            metadata: v.metadata,
            operation: WalOperation::Insert,
            timestamp: Utc::now(),
            sequence_number: 0, // Set by WAL
        })
        .collect();
    
    // 4. Write to assigned WAL directory
    let mut sequence_numbers = Vec::new();
    for entry in wal_entries {
        let sequence = self.wal_manager
            .write_entry_to_assigned_disk(collection_id, entry, &assignment)
            .await?;
        sequence_numbers.push(sequence);
    }
    
    // 5. Check flush thresholds and trigger background flush if needed
    self.check_and_trigger_flush(collection_id, &assignment).await?;
    
    Ok(InsertResult {
        inserted_count: sequence_numbers.len(),
        sequence_numbers,
        assignment_info: Some(assignment),
    })
}
----

=== 2.4 Recovery Architecture

==== Assignment Discovery Process
[source,rust]
----
pub struct RecoveryManager {
    assignment_service: Arc<dyn AssignmentService>,
    wal_strategies: Vec<Arc<dyn WalStrategy>>,
    filesystem: Arc<FilesystemFactory>,
}

impl RecoveryManager {
    pub async fn recover_from_crash(&self, config: &Config) -> Result<RecoveryResult> {
        let mut recovery_result = RecoveryResult::new();
        
        // Step 1: Discover assignments from filesystem
        let discovered_assignments = self.discover_assignments(config).await?;
        recovery_result.assignments_recovered = discovered_assignments.len();
        
        // Step 2: Recover WAL entries from all strategies
        for strategy in &self.wal_strategies {
            let wal_recovery = self.recover_wal_strategy(strategy.as_ref(), config).await?;
            recovery_result.merge_wal_recovery(wal_recovery);
        }
        
        // Step 3: Rebuild in-memory structures
        self.rebuild_memtables(&recovery_result.wal_entries).await?;
        
        // Step 4: Verify data integrity
        self.verify_recovery_integrity(&recovery_result).await?;
        
        Ok(recovery_result)
    }
    
    async fn discover_assignments(&self, config: &Config) -> Result<Vec<StorageAssignmentResult>> {
        let mut discovered = Vec::new();
        
        // Scan all configured WAL directories
        for (index, wal_url) in config.storage.wal_config.wal_urls.iter().enumerate() {
            let filesystem = self.filesystem.get_backend(wal_url)?;
            
            // Convert URL to path for local filesystem
            let path = if wal_url.starts_with("file://") {
                wal_url.strip_prefix("file://").unwrap_or(wal_url)
            } else {
                wal_url
            };
            
            // List collections in this directory
            let collections = filesystem.list(path).await?;
            
            for collection_id in collections {
                // Record assignment for discovered collection
                let assignment = StorageAssignmentResult {
                    storage_url: wal_url.clone(),
                    directory_index: index,
                    assigned_at: Utc::now(),
                };
                
                self.assignment_service.record_assignment(
                    &CollectionId::from(collection_id),
                    StorageComponentType::Wal,
                    assignment.clone(),
                ).await?;
                
                discovered.push(assignment);
            }
        }
        
        Ok(discovered)
    }
}
----

== 3. Development Guidelines

=== 3.1 Code Organization

==== Module Structure
```
src/
├── services/           # Business logic layer
│   ├── collection_service.rs
│   ├── unified_avro_service.rs
│   └── mod.rs
├── storage/           # Storage abstraction layer
│   ├── assignment_service.rs  # NEW: Assignment service
│   ├── persistence/
│   │   └── wal/
│   │       ├── avro.rs        # Avro WAL strategy
│   │       ├── bincode.rs     # Bincode WAL strategy
│   │       └── mod.rs         # Base WAL strategy trait
│   └── mod.rs
├── network/           # API layer
│   ├── grpc/
│   ├── rest/
│   └── mod.rs
└── core/             # Shared types and utilities
    ├── error.rs
    ├── config.rs
    └── mod.rs
```

==== Naming Conventions
* **Modules**: `snake_case`
* **Structs/Enums**: `PascalCase`
* **Functions/Variables**: `snake_case`
* **Constants**: `SCREAMING_SNAKE_CASE`
* **Traits**: `PascalCase` (descriptive names like `AssignmentService`)

=== 3.2 Error Handling

==== Unified Error Type
[source,rust]
----
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ProximaDBError {
    NotFound(String),
    AlreadyExists(String),
    InvalidInput(String),
    Internal(String),
    StorageError(String),
    ConfigurationError(String),
    NetworkError(String),
    SerializationError(String),
    IndexError(String),
    ConcurrencyError(String),
}

impl ProximaDBError {
    pub fn error_code(&self) -> u32 {
        match self {
            ProximaDBError::NotFound(_) => 404,
            ProximaDBError::AlreadyExists(_) => 409,
            ProximaDBError::InvalidInput(_) => 400,
            ProximaDBError::Internal(_) => 500,
            ProximaDBError::StorageError(_) => 503,
            ProximaDBError::ConfigurationError(_) => 500,
            ProximaDBError::NetworkError(_) => 502,
            ProximaDBError::SerializationError(_) => 422,
            ProximaDBError::IndexError(_) => 500,
            ProximaDBError::ConcurrencyError(_) => 409,
        }
    }
}
----

=== 3.3 Testing Guidelines

==== Unit Tests for Assignment Service
[source,rust]
----
#[cfg(test)]
mod tests {
    use super::*;
    use tokio::test as async_test;

    #[async_test]
    async fn test_round_robin_assignment() {
        let service = RoundRobinAssignmentService::new();
        let config = StorageAssignmentConfig {
            storage_urls: vec![
                "file:///disk1".to_string(),
                "file:///disk2".to_string(),
                "file:///disk3".to_string(),
            ],
            component_type: StorageComponentType::Wal,
            collection_affinity: false,
        };
        
        // Test round-robin behavior
        let assignment1 = service.assign_storage_url(
            &CollectionId::from("collection1".to_string()),
            &config
        ).await.unwrap();
        
        let assignment2 = service.assign_storage_url(
            &CollectionId::from("collection2".to_string()),
            &config
        ).await.unwrap();
        
        let assignment3 = service.assign_storage_url(
            &CollectionId::from("collection3".to_string()),
            &config
        ).await.unwrap();
        
        // Verify round-robin distribution
        assert_eq!(assignment1.directory_index, 0);
        assert_eq!(assignment2.directory_index, 1);
        assert_eq!(assignment3.directory_index, 2);
        
        // Test assignment persistence
        let retrieved = service.get_assignment(
            &CollectionId::from("collection1".to_string()),
            StorageComponentType::Wal
        ).await;
        
        assert!(retrieved.is_some());
        assert_eq!(retrieved.unwrap().storage_url, "file:///disk1");
    }
    
    #[async_test]
    async fn test_collection_affinity() {
        let service = RoundRobinAssignmentService::new();
        let config = StorageAssignmentConfig {
            storage_urls: vec![
                "file:///disk1".to_string(),
                "file:///disk2".to_string(),
                "file:///disk3".to_string(),
            ],
            component_type: StorageComponentType::Wal,
            collection_affinity: true,
        };
        
        // Same collection should get same assignment
        let assignment1 = service.assign_storage_url(
            &CollectionId::from("same_collection".to_string()),
            &config
        ).await.unwrap();
        
        let assignment2 = service.assign_storage_url(
            &CollectionId::from("same_collection".to_string()),
            &config
        ).await.unwrap();
        
        assert_eq!(assignment1.storage_url, assignment2.storage_url);
        assert_eq!(assignment1.directory_index, assignment2.directory_index);
    }
}
----

==== Integration Tests
[source,rust]
----
#[cfg(test)]
mod integration_tests {
    use super::*;
    use tempfile::TempDir;

    #[async_test]
    async fn test_multi_disk_end_to_end() {
        // Setup test environment with multiple disks
        let temp_dirs: Vec<TempDir> = (0..3).map(|_| TempDir::new().unwrap()).collect();
        let wal_urls: Vec<String> = temp_dirs
            .iter()
            .map(|dir| format!("file://{}/wal", dir.path().display()))
            .collect();
        
        let config = create_test_config_with_multiple_disks(wal_urls);
        
        // Initialize services
        let assignment_service = Arc::new(RoundRobinAssignmentService::new());
        let wal_strategy = Arc::new(AvroWalStrategy::new(assignment_service.clone()));
        let unified_service = UnifiedAvroService::new(wal_strategy);
        
        // Test vector insert with automatic assignment
        let vectors = vec![
            VectorInsertRequest {
                id: "test1".to_string(),
                vector: vec![0.1, 0.2, 0.3, 0.4],
                metadata: HashMap::new(),
            },
            VectorInsertRequest {
                id: "test2".to_string(),
                vector: vec![0.5, 0.6, 0.7, 0.8],
                metadata: HashMap::new(),
            }
        ];
        
        let result = unified_service.handle_vector_insert_v2(
            "test_collection",
            vectors
        ).await;
        
        assert!(result.is_ok());
        
        // Verify assignment was created
        let assignment = assignment_service.get_assignment(
            &CollectionId::from("test_collection".to_string()),
            StorageComponentType::Wal
        ).await;
        
        assert!(assignment.is_some());
        
        // Verify data was written to assigned disk
        let assignment = assignment.unwrap();
        let disk_path = assignment.storage_url.strip_prefix("file://").unwrap();
        let collection_path = format!("{}/test_collection", disk_path);
        
        assert!(std::path::Path::new(&collection_path).exists());
    }
}
----

== 4. Building and Testing

=== 4.1 Build Commands

[source,bash]
----
# Development build
cargo build

# Release build with optimizations
cargo build --release

# Server-optimized build
cargo build --profile release-server

# Build with SIMD optimizations
cargo build --features simd --release

# Using Makefile shortcuts
make build          # Development build
make build-release  # Release build
make build-server   # Optimized server build
----

=== 4.2 Testing Commands

[source,bash]
----
# Run all tests
cargo test

# Run with output capture
cargo test -- --nocapture

# Run assignment service tests specifically
cargo test assignment

# Run multi-disk integration tests
cargo test multi_disk

# Run WAL strategy tests
cargo test wal_strategy

# Python SDK tests with multi-disk
cd clients/python && pytest tests/integration/test_multi_disk.py

# Combined test suite
make test
----

=== 4.3 Multi-Disk Specific Testing

[source,bash]
----
# Test assignment service functionality
cargo test storage::assignment_service

# Test WAL strategy pattern
cargo test storage::persistence::wal

# Test recovery mechanisms
cargo test recovery

# Test configuration validation
cargo test config::multi_disk

# Integration test with real multi-disk setup
RUST_LOG=debug cargo test test_multi_disk_end_to_end -- --nocapture
----

== 5. Configuration Management

=== 5.1 Multi-Disk Configuration Structure

[source,rust]
----
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct WalConfig {
    pub wal_urls: Vec<String>,
    pub distribution_strategy: DistributionStrategy,
    pub collection_affinity: bool,
    pub memory_flush_size_bytes: usize,
    pub global_flush_threshold: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum DistributionStrategy {
    LoadBalanced,    // Round-robin (default)
    HashBased,       // Consistent hashing
    PerformanceBased, // Based on disk performance
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StorageAssignmentConfig {
    pub storage_urls: Vec<String>,
    pub component_type: StorageComponentType,
    pub collection_affinity: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StorageAssignmentResult {
    pub storage_url: String,
    pub directory_index: usize,
    pub assigned_at: DateTime<Utc>,
}
----

=== 5.2 Configuration Validation

[source,rust]
----
impl WalConfig {
    pub fn validate(&self) -> Result<()> {
        // Validate WAL URLs
        if self.wal_urls.is_empty() {
            return Err(ProximaDBError::ConfigurationError(
                "At least one WAL URL must be configured".into()
            ));
        }
        
        for url in &self.wal_urls {
            self.validate_storage_url(url)?;
        }
        
        // Validate memory settings
        if self.memory_flush_size_bytes == 0 {
            return Err(ProximaDBError::ConfigurationError(
                "Memory flush size must be greater than 0".into()
            ));
        }
        
        if self.global_flush_threshold < self.memory_flush_size_bytes {
            return Err(ProximaDBError::ConfigurationError(
                "Global flush threshold must be >= memory flush size".into()
            ));
        }
        
        Ok(())
    }
    
    fn validate_storage_url(&self, url: &str) -> Result<()> {
        if !url.starts_with("file://") && 
           !url.starts_with("s3://") && 
           !url.starts_with("adls://") && 
           !url.starts_with("gcs://") {
            return Err(ProximaDBError::ConfigurationError(
                format!("Invalid storage URL: {}. Must start with file://, s3://, adls://, or gcs://", url)
            ));
        }
        
        // Validate file:// URLs have correct format
        if url.starts_with("file://") && !url.starts_with("file:///") {
            return Err(ProximaDBError::ConfigurationError(
                format!("Invalid file URL: {}. Must use file:///absolute/path format", url)
            ));
        }
        
        Ok(())
    }
}
----

== 6. Performance Optimization

=== 6.1 Assignment Service Optimization

[source,rust]
----
// Optimized assignment lookup with caching
impl RoundRobinAssignmentService {
    async fn get_assignment_cached(
        &self,
        collection_id: &CollectionId,
        component_type: StorageComponentType,
    ) -> Option<StorageAssignmentResult> {
        // Fast read-only access for existing assignments
        let assignments = self.assignments.read().await;
        
        assignments
            .get(&component_type)
            .and_then(|type_assignments| type_assignments.get(collection_id))
            .cloned()
    }
    
    async fn batch_assign_collections(
        &self,
        collection_ids: &[CollectionId],
        config: &StorageAssignmentConfig,
    ) -> Result<Vec<StorageAssignmentResult>> {
        let mut results = Vec::with_capacity(collection_ids.len());
        
        // Batch process assignments to minimize lock contention
        for collection_id in collection_ids {
            let assignment = self.assign_storage_url(collection_id, config).await?;
            results.push(assignment);
        }
        
        Ok(results)
    }
}
----

=== 6.2 WAL Performance Optimization

[source,rust]
----
// Concurrent WAL writes to multiple disks
pub async fn parallel_wal_writes(
    &self,
    entries_by_assignment: HashMap<StorageAssignmentResult, Vec<WalEntry>>,
) -> Result<Vec<u64>> {
    let write_tasks: Vec<_> = entries_by_assignment
        .into_iter()
        .map(|(assignment, entries)| {
            let wal_strategy = self.wal_strategy.clone();
            
            tokio::spawn(async move {
                wal_strategy.write_entries_to_disk(&assignment, entries).await
            })
        })
        .collect();
    
    let results = join_all(write_tasks).await;
    let mut all_sequences = Vec::new();
    
    for result in results {
        match result {
            Ok(Ok(sequences)) => all_sequences.extend(sequences),
            Ok(Err(e)) => return Err(e),
            Err(e) => return Err(ProximaDBError::Internal(e.to_string())),
        }
    }
    
    Ok(all_sequences)
}
----

== 7. Monitoring and Debugging

=== 7.1 Assignment Service Monitoring

[source,rust]
----
impl RoundRobinAssignmentService {
    pub async fn get_assignment_stats(&self) -> Result<serde_json::Value> {
        let assignments = self.assignments.read().await;
        let counters = self.round_robin_counters.read().await;
        
        let mut stats = serde_json::Map::new();
        
        for (component_type, type_assignments) in assignments.iter() {
            let mut component_stats = serde_json::Map::new();
            
            // Total assignments
            component_stats.insert(
                "total_assignments".to_string(),
                serde_json::Value::Number(type_assignments.len().into())
            );
            
            // Directory distribution
            let mut distribution = HashMap::new();
            for assignment in type_assignments.values() {
                *distribution.entry(assignment.directory_index).or_insert(0) += 1;
            }
            
            component_stats.insert(
                "directory_distribution".to_string(),
                serde_json::to_value(distribution)?
            );
            
            // Current counter
            if let Some(counter) = counters.get(component_type) {
                component_stats.insert(
                    "current_counter".to_string(),
                    serde_json::Value::Number((*counter).into())
                );
            }
            
            stats.insert(
                format!("{:?}", component_type).to_lowercase(),
                serde_json::Value::Object(component_stats)
            );
        }
        
        Ok(serde_json::Value::Object(stats))
    }
}
----

=== 7.2 Debug Logging

[source,rust]
----
use tracing::{info, warn, error, debug, span, Level};

impl RoundRobinAssignmentService {
    async fn assign_storage_url_with_logging(
        &self,
        collection_id: &CollectionId,
        config: &StorageAssignmentConfig,
    ) -> Result<StorageAssignmentResult> {
        let span = span!(
            Level::INFO, 
            "assignment", 
            collection_id = %collection_id,
            component_type = ?config.component_type
        );
        let _enter = span.enter();
        
        debug!("Starting assignment process");
        
        // Check for existing assignment
        if let Some(existing) = self.get_assignment(collection_id, config.component_type).await {
            info!(
                storage_url = %existing.storage_url,
                directory_index = existing.directory_index,
                "Using existing assignment"
            );
            return Ok(existing);
        }
        
        // Create new assignment
        let index = if config.collection_affinity {
            let hash_index = self.hash_collection_id(collection_id) % config.storage_urls.len();
            info!(hash_index = hash_index, "Using affinity-based assignment");
            hash_index
        } else {
            let rr_index = self.get_next_round_robin_index(config.component_type, &config.storage_urls).await?;
            info!(round_robin_index = rr_index, "Using round-robin assignment");
            rr_index
        };
        
        let assignment = StorageAssignmentResult {
            storage_url: config.storage_urls[index].clone(),
            directory_index: index,
            assigned_at: Utc::now(),
        };
        
        // Record assignment
        self.record_assignment(collection_id, config.component_type, assignment.clone()).await?;
        
        info!(
            storage_url = %assignment.storage_url,
            directory_index = assignment.directory_index,
            "Created new assignment"
        );
        
        Ok(assignment)
    }
}
----

== 8. Contributing Guidelines

=== 8.1 Development Workflow

1. **Fork and Clone**: Fork the repository and clone your fork
2. **Create Feature Branch**: Create a branch from `main` for your changes
3. **Implement Changes**: Follow coding guidelines and write comprehensive tests
4. **Test Multi-Disk Functionality**: Ensure all multi-disk tests pass
5. **Update Documentation**: Update relevant documentation and diagrams
6. **Commit Changes**: Use conventional commit messages
7. **Submit PR**: Create pull request with clear description

=== 8.2 Multi-Disk Specific Guidelines

==== Assignment Service Changes
* Always maintain backward compatibility in assignment logic
* Add comprehensive tests for new assignment strategies
* Document performance implications of changes
* Consider impact on existing assignments during recovery

==== WAL Strategy Changes
* Ensure all strategies implement the base trait correctly
* Test serialization/deserialization thoroughly
* Verify assignment service integration
* Document strategy-specific behaviors

==== Configuration Changes
* Add validation for new configuration options
* Provide migration path for existing configurations
* Document configuration impact on performance
* Test with both single and multi-disk setups

=== 8.3 Commit Message Format

[source]
----
<type>(<scope>): <subject>

<body>

<footer>
----

Examples specific to multi-disk work:
* `feat(assignment): implement hash-based distribution strategy`
* `fix(wal): resolve URL path conversion for Windows`
* `docs(config): update multi-disk configuration examples`
* `test(assignment): add comprehensive round-robin tests`
* `perf(wal): optimize parallel writes to multiple disks`

== Conclusion

This developer guide provides comprehensive coverage of ProximaDB's multi-disk architecture, focusing on the assignment service and WAL strategy pattern that enable enterprise-grade performance and reliability. The layered approach ensures maintainability while the pluggable design allows for future enhancements.

Key architectural principles:
* **Assignment Service**: Intelligent collection-to-disk mapping with multiple strategies
* **WAL Strategy Pattern**: Pluggable serialization with consistent assignment integration
* **Recovery Mechanisms**: Robust discovery and recovery for high availability
* **Performance Optimization**: Parallel operations and efficient resource utilization

For questions about the multi-disk architecture or to contribute improvements, engage with the development team through GitHub issues or discussions.