= ProximaDB Low-Level Design (LLD)
:toc:
:toc-placement: preamble
:icons: font
:source-highlighter: highlight.js
:imagesdir: diagrams/images

== Overview

This document provides detailed low-level design specifications for ProximaDB's implementation, covering technical architecture, data structures, algorithms, and implementation patterns.

== 1. Multi-Disk Storage Architecture

=== 1.1 Assignment Service Implementation

The Assignment Service implements intelligent collection-to-disk mapping using a round-robin strategy with affinity support.

image::Assignment Service Flow.png[Assignment Service Flow, align="center"]

==== Core Data Structures

[source,rust]
----
pub struct RoundRobinAssignmentService {
    assignments: Arc<RwLock<HashMap<StorageComponentType, HashMap<CollectionId, StorageAssignmentResult>>>>,
    round_robin_counters: Arc<RwLock<HashMap<StorageComponentType, usize>>>,
}

pub struct StorageAssignmentResult {
    pub storage_url: String,
    pub directory_index: usize,
    pub assigned_at: DateTime<Utc>,
}

pub enum StorageComponentType {
    Wal,
    Viper,
    Lsm,
    Index,
    Metadata,
}
----

==== Assignment Algorithm

===== Round-Robin Distribution
[source,rust]
----
async fn get_next_round_robin_index(
    &self,
    component_type: StorageComponentType,
    storage_urls: &[String],
) -> Result<usize> {
    let mut counters = self.round_robin_counters.write().await;
    let counter = counters.entry(component_type).or_insert(0);
    let index = *counter % storage_urls.len();
    *counter = (*counter + 1) % storage_urls.len();
    Ok(index)
}
----

===== Collection Affinity Algorithm
[source,rust]
----
fn hash_collection_id(&self, collection_id: &CollectionId) -> usize {
    let mut hasher = DefaultHasher::new();
    collection_id.hash(&mut hasher);
    hasher.finish() as usize
}

async fn assign_with_affinity(
    &self,
    collection_id: &CollectionId,
    storage_urls: &[String],
) -> Result<usize> {
    let hash = self.hash_collection_id(collection_id);
    Ok(hash % storage_urls.len())
}
----

=== 1.2 WAL Strategy Pattern Implementation

image::WAL Strategy Pattern.png[WAL Strategy Pattern, align="center"]

The WAL layer implements a strategy pattern with base trait providing common assignment logic.

==== Base WAL Strategy Trait
[source,rust]
----
#[async_trait]
pub trait WalStrategy: Send + Sync {
    fn strategy_name(&self) -> &'static str;
    fn get_assignment_service(&self) -> &Arc<dyn AssignmentService>;
    
    async fn select_wal_url_for_collection(
        &self,
        collection_id: &str,
        config: &WalConfig,
    ) -> Result<String> {
        // Check existing assignment
        if let Some(assignment) = self.get_assignment_service()
            .get_assignment(
                &CollectionId::from(collection_id.to_string()),
                StorageComponentType::Wal,
            )
            .await
        {
            return Ok(assignment.storage_url);
        }
        
        // Create new assignment using service
        let assignment_config = StorageAssignmentConfig {
            storage_urls: config.wal_urls.clone(),
            component_type: StorageComponentType::Wal,
            collection_affinity: config.collection_affinity,
        };
        
        let assignment = self.get_assignment_service()
            .assign_storage_url(
                &CollectionId::from(collection_id.to_string()),
                &assignment_config,
            )
            .await?;
            
        Ok(assignment.storage_url)
    }
}
----

=== 1.3 URL-to-Path Conversion Implementation

Critical for multi-cloud storage support, converting URLs to proper filesystem paths.

[source,rust]
----
pub fn convert_url_to_path(url: &str) -> Result<String> {
    if url.starts_with("file://") {
        Ok(url.strip_prefix("file://").unwrap_or(url).to_string())
    } else if url.starts_with("s3://") {
        // S3 URLs handled by specific filesystem backend
        Ok(url.to_string())
    } else if url.starts_with("adls://") {
        // Azure Data Lake URLs handled by specific filesystem backend
        Ok(url.to_string())
    } else if url.starts_with("gcs://") {
        // Google Cloud Storage URLs handled by specific filesystem backend
        Ok(url.to_string())
    } else {
        // Assume local path
        Ok(url.to_string())
    }
}
----

== 2. WAL Memory Management

=== 2.1 ART Memtable Implementation

The WAL uses Adaptive Radix Trees (ART) for efficient in-memory vector storage.

[source,rust]
----
pub struct WalMemTable {
    collections: Arc<RwLock<HashMap<String, CollectionMemTable>>>,
    global_sequence: Arc<AtomicU64>,
    memory_usage: Arc<AtomicUsize>,
}

pub struct CollectionMemTable {
    entries: art::Art<String, WalEntry>,
    sequence_counter: AtomicU64,
    memory_size: AtomicUsize,
    last_flush: Arc<RwLock<Instant>>,
}

impl WalMemTable {
    pub async fn insert_entry(
        &self,
        collection_id: &str,
        vector_id: &str,
        entry: WalEntry,
    ) -> Result<u64> {
        let mut collections = self.collections.write().await;
        let collection_table = collections
            .entry(collection_id.to_string())
            .or_insert_with(CollectionMemTable::new);
        
        let sequence = self.global_sequence.fetch_add(1, Ordering::SeqCst);
        let mut entry_with_seq = entry;
        entry_with_seq.sequence_number = sequence;
        
        // Insert into ART
        collection_table.entries.insert(
            vector_id.to_string(),
            entry_with_seq.clone(),
        );
        
        // Update memory tracking
        let entry_size = self.estimate_entry_size(&entry_with_seq);
        collection_table.memory_size.fetch_add(entry_size, Ordering::SeqCst);
        self.memory_usage.fetch_add(entry_size, Ordering::SeqCst);
        
        Ok(sequence)
    }
}
----

=== 2.2 Flush Threshold Management

[source,rust]
----
pub struct FlushThresholdManager {
    collection_thresholds: HashMap<String, usize>,
    global_threshold: usize,
    memory_pressure_threshold: usize,
}

impl FlushThresholdManager {
    pub fn should_flush_collection(
        &self,
        collection_id: &str,
        current_size: usize,
    ) -> bool {
        let threshold = self.collection_thresholds
            .get(collection_id)
            .unwrap_or(&self.global_threshold);
        current_size >= *threshold
    }
    
    pub fn should_flush_global(&self, total_memory: usize) -> bool {
        total_memory >= self.memory_pressure_threshold
    }
}
----

== 3. VIPER Storage Engine

=== 3.1 Parquet-Based Vector Storage

The VIPER engine uses Apache Parquet for columnar vector storage with compression.

[source,rust]
----
pub struct ViperEngine {
    parquet_writer: Arc<RwLock<Option<ParquetWriter<File>>>>,
    compression: CompressionCodec,
    schema: Arc<Schema>,
    filesystem: Arc<FilesystemFactory>,
}

impl ViperEngine {
    pub async fn write_vectors(
        &self,
        collection_id: &str,
        vectors: &[VectorRecord],
    ) -> Result<WriteResult> {
        let schema = self.build_vector_schema(vectors)?;
        let storage_url = self.get_storage_url(collection_id).await?;
        
        let mut writer = self.create_parquet_writer(&storage_url, &schema).await?;
        
        // Write vectors in columnar format
        for chunk in vectors.chunks(BATCH_SIZE) {
            let batch = self.vectors_to_record_batch(chunk, &schema)?;
            writer.write(&batch)?;
        }
        
        writer.close()?;
        
        Ok(WriteResult {
            records_written: vectors.len(),
            bytes_written: writer.bytes_written(),
            compression_ratio: writer.compression_ratio(),
        })
    }
}
----

== 4. Data Flow and Persistence

image::Data Flow and Persistence.png[Data Flow and Persistence, align="center"]

=== 4.1 Write Path Implementation

The complete write path from API request to persistent storage:

[source,rust]
----
pub async fn handle_vector_insert_pipeline(
    &self,
    collection_id: &str,
    vectors: Vec<VectorInsertRequest>,
) -> Result<InsertResult> {
    // Step 1: Validate collection exists
    let collection = self.collection_service
        .get_collection_by_name_or_uuid(collection_id)
        .await?
        .ok_or(ProximaDBError::NotFound(format!("Collection {}", collection_id)))?;
    
    // Step 2: Get assignment for this collection
    let assignment = self.assignment_service
        .get_assignment(&CollectionId::from(collection_id.to_string()), StorageComponentType::Wal)
        .await
        .ok_or(ProximaDBError::Internal("No WAL assignment found".into()))?;
    
    // Step 3: Convert to WAL entries
    let wal_entries: Vec<WalEntry> = vectors.into_iter()
        .map(|v| WalEntry {
            vector_id: v.id,
            vector: v.vector,
            metadata: v.metadata,
            operation: WalOperation::Insert,
            timestamp: Utc::now(),
            sequence_number: 0, // Will be set by WAL
        })
        .collect();
    
    // Step 4: Write to WAL (memory + eventual disk flush)
    let mut sequence_numbers = Vec::new();
    for entry in wal_entries {
        let sequence = self.wal_manager
            .write_entry(collection_id, entry)
            .await?;
        sequence_numbers.push(sequence);
    }
    
    // Step 5: Check flush thresholds
    self.check_and_trigger_flush(collection_id).await?;
    
    Ok(InsertResult {
        inserted_count: sequence_numbers.len(),
        sequence_numbers,
    })
}
----

=== 4.2 Recovery Implementation

[source,rust]
----
pub struct RecoveryManager {
    assignment_service: Arc<dyn AssignmentService>,
    wal_strategies: Vec<Arc<dyn WalStrategy>>,
    filesystem: Arc<FilesystemFactory>,
}

impl RecoveryManager {
    pub async fn recover_from_crash(&self, config: &Config) -> Result<RecoveryResult> {
        let mut recovery_result = RecoveryResult::new();
        
        // Step 1: Discover assignments from filesystem
        let discovered_assignments = self.discover_assignments(config).await?;
        recovery_result.assignments_recovered = discovered_assignments.len();
        
        // Step 2: Recover WAL entries from all strategies
        for strategy in &self.wal_strategies {
            let wal_recovery = self.recover_wal_strategy(strategy.as_ref(), config).await?;
            recovery_result.merge_wal_recovery(wal_recovery);
        }
        
        // Step 3: Rebuild in-memory structures
        self.rebuild_memtables(&recovery_result.wal_entries).await?;
        
        // Step 4: Verify data integrity
        self.verify_recovery_integrity(&recovery_result).await?;
        
        Ok(recovery_result)
    }
}
----

== 5. Configuration Management

=== 5.1 Multi-Disk Configuration Structure

[source,toml]
----
[storage.wal_config]
wal_urls = [
    "file:///data/disk1/wal",
    "file:///data/disk2/wal", 
    "file:///data/disk3/wal"
]
distribution_strategy = "LoadBalanced"  # or "HashBased", "PerformanceBased"
collection_affinity = true
memory_flush_size_bytes = 1048576  # 1MB
global_flush_threshold = 536870912  # 512MB

[[storage.storage_layout.base_paths]]
base_dir = "/data/disk1/storage"
instance_id = 1
mount_point = "/mnt/disk1"
disk_type = { NvmeSsd = { max_iops = 100000 } }
capacity_config = { 
    max_wal_size_mb = 2048, 
    metadata_reserved_mb = 512, 
    warning_threshold_percent = 85.0 
}

[storage.metadata_backend]
backend_type = "filestore"
storage_url = "file:///data/disk1/metadata"
cache_size_mb = 128
flush_interval_secs = 30
----

=== 5.2 Configuration Validation

[source,rust]
----
pub struct ConfigValidator {
    required_fields: HashSet<String>,
    url_validators: HashMap<String, Box<dyn UrlValidator>>,
}

impl ConfigValidator {
    pub fn validate_config(&self, config: &Config) -> Result<Vec<ValidationWarning>> {
        let mut warnings = Vec::new();
        
        // Validate WAL URLs
        for url in &config.storage.wal_config.wal_urls {
            if let Err(e) = self.validate_storage_url(url) {
                return Err(ProximaDBError::ConfigurationError(
                    format!("Invalid WAL URL '{}': {}", url, e)
                ));
            }
        }
        
        // Validate disk configuration consistency
        if config.storage.storage_layout.base_paths.is_empty() {
            return Err(ProximaDBError::ConfigurationError(
                "No storage paths configured".into()
            ));
        }
        
        Ok(warnings)
    }
}
----

== 6. Error Handling and Recovery

=== 6.1 Unified Error Types

[source,rust]
----
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ProximaDBError {
    NotFound(String),
    AlreadyExists(String),
    InvalidInput(String),
    Internal(String),
    StorageError(String),
    ConfigurationError(String),
    NetworkError(String),
    SerializationError(String),
    IndexError(String),
    ConcurrencyError(String),
}

impl ProximaDBError {
    pub fn error_code(&self) -> u32 {
        match self {
            ProximaDBError::NotFound(_) => 404,
            ProximaDBError::AlreadyExists(_) => 409,
            ProximaDBError::InvalidInput(_) => 400,
            ProximaDBError::Internal(_) => 500,
            ProximaDBError::StorageError(_) => 503,
            ProximaDBError::ConfigurationError(_) => 500,
            ProximaDBError::NetworkError(_) => 502,
            ProximaDBError::SerializationError(_) => 422,
            ProximaDBError::IndexError(_) => 500,
            ProximaDBError::ConcurrencyError(_) => 409,
        }
    }
}
----

== 7. Performance Optimizations

=== 7.1 Zero-Copy Avro Operations

[source,rust]
----
pub struct ZeroCopyAvroProcessor {
    schema: Arc<avro_rs::Schema>,
    reader_pool: ObjectPool<avro_rs::Reader<Cursor<Vec<u8>>>>,
    writer_pool: ObjectPool<avro_rs::Writer<Vec<u8>>>,
}

impl ZeroCopyAvroProcessor {
    pub async fn process_vector_batch(
        &self,
        avro_payload: &[u8],
    ) -> Result<Vec<ProcessedVector>> {
        let mut reader = self.reader_pool.get().await;
        reader.reset(Cursor::new(avro_payload.to_vec()))?;
        
        let mut vectors = Vec::new();
        for value in reader.values() {
            let vector = self.deserialize_vector_zero_copy(value?)?;
            vectors.push(vector);
        }
        
        Ok(vectors)
    }
}
----

=== 7.2 Memory Pool Management

[source,rust]
----
pub struct MemoryPoolManager {
    vector_pools: HashMap<usize, ObjectPool<Vec<f32>>>,
    buffer_pools: HashMap<usize, ObjectPool<Vec<u8>>>,
    metadata_pool: ObjectPool<HashMap<String, serde_json::Value>>,
}

impl MemoryPoolManager {
    pub fn get_vector_buffer(&self, dimension: usize) -> Vec<f32> {
        if let Some(pool) = self.vector_pools.get(&dimension) {
            if let Ok(mut buffer) = pool.try_get() {
                buffer.clear();
                buffer.reserve_exact(dimension);
                return buffer;
            }
        }
        
        Vec::with_capacity(dimension)
    }
}
----

This LLD document provides comprehensive technical implementation details covering the multi-disk architecture, WAL management, storage engines, data flow, configuration management, error handling, and performance optimizations that form the foundation of ProximaDB's low-level implementation.