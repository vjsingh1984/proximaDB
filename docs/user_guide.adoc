= ProximaDB User Guide
:toc:
:toc-placement: preamble
:icons: font
:source-highlighter: highlight.js
:imagesdir: diagrams/images

== Introduction

ProximaDB is a cloud-native vector database designed for high-performance similarity search and AI applications. This user guide provides comprehensive instructions for installation, configuration, and usage with the multi-disk assignment service.

== 1. Quick Start

=== 1.1 Installation

==== Using Docker (Recommended)
[source,bash]
----
# Pull the latest ProximaDB image
docker pull proximadb/proximadb:latest

# Run with default configuration
docker run -p 5678:5678 -p 5679:5679 -v /data:/data proximadb/proximadb:latest
----

==== From Source
[source,bash]
----
# Clone repository
git clone https://github.com/proximadb/proximadb.git
cd proximadb

# Build and run
cargo build --release
cargo run --bin proximadb-server
----

=== 1.2 First Steps

Once ProximaDB is running, you can access:
* **REST API**: http://localhost:5678
* **gRPC API**: localhost:5679
* **Health Check**: http://localhost:5678/health

=== 1.3 Creating Your First Collection

==== Using REST API
[source,bash]
----
# Create a collection for 384-dimensional vectors
curl -X POST http://localhost:5678/collections \
  -H "Content-Type: application/json" \
  -d '{
    "name": "documents",
    "dimension": 384,
    "distance_metric": "cosine"
  }'
----

==== Using Python SDK
[source,python]
----
from proximadb import ProximaDBClient

# Connect to ProximaDB
client = ProximaDBClient("localhost:5678")

# Create collection
collection = client.create_collection(
    name="documents",
    dimension=384,
    distance_metric="cosine"
)
----

== 2. Multi-Disk Configuration

=== 2.1 Basic Configuration

ProximaDB uses TOML configuration files. The default configuration supports single-disk setup:

[source,toml]
----
[server]
rest_port = 5678
grpc_port = 5679
host = "localhost"

[storage.wal_config]
wal_urls = ["file:///data/proximadb/wal"]
memory_flush_size_bytes = 1048576  # 1MB
----

=== 2.2 Multi-Disk Production Configuration

For production deployments, configure multiple disks for improved performance and reliability:

[source,toml]
----
[storage.wal_config]
wal_urls = [
    "file:///data/disk1/wal",
    "file:///data/disk2/wal", 
    "file:///data/disk3/wal"
]
distribution_strategy = "LoadBalanced"
collection_affinity = true
memory_flush_size_bytes = 1048576
global_flush_threshold = 536870912  # 512MB

[[storage.storage_layout.base_paths]]
base_dir = "/data/disk1/storage"
instance_id = 1
mount_point = "/mnt/disk1"
disk_type = { NvmeSsd = { max_iops = 100000 } }
capacity_config = { 
    max_wal_size_mb = 2048, 
    metadata_reserved_mb = 512, 
    warning_threshold_percent = 85.0 
}

[[storage.storage_layout.base_paths]]
base_dir = "/data/disk2/storage"
instance_id = 2
mount_point = "/mnt/disk2"
disk_type = { NvmeSsd = { max_iops = 100000 } }
capacity_config = { 
    max_wal_size_mb = 2048, 
    metadata_reserved_mb = 512, 
    warning_threshold_percent = 85.0 
}

[storage.metadata_backend]
backend_type = "filestore"
storage_url = "file:///data/disk1/metadata"
cache_size_mb = 128
flush_interval_secs = 30
----

=== 2.3 Cloud Storage Configuration

==== AWS S3
[source,toml]
----
[storage.wal_config]
wal_urls = [
    "s3://proximadb-wal-us-east-1/cluster1",
    "s3://proximadb-wal-us-west-2/cluster1",
    "s3://proximadb-wal-eu-west-1/cluster1"
]

[[storage.storage_layout.base_paths]]
base_dir = "s3://proximadb-storage-us-east-1/cluster1"
instance_id = 1
mount_point = "us-east-1"
disk_type = { NetworkStorage = { latency_ms = 10.0 } }

[storage.metadata_backend]
storage_url = "s3://proximadb-metadata/cluster1"

[storage.metadata_backend.cloud_config.s3_config]
region = "us-east-1"
bucket = "proximadb-metadata"
use_iam_role = true
----

==== Azure Blob Storage
[source,toml]
----
[storage.wal_config]
wal_urls = [
    "adls://proximadb1.dfs.core.windows.net/wal/cluster1",
    "adls://proximadb2.dfs.core.windows.net/wal/cluster1"
]

[storage.metadata_backend]
storage_url = "adls://proximadbmeta.dfs.core.windows.net/metadata"

[storage.metadata_backend.cloud_config.azure_config]
account_name = "proximadbmeta"
container = "metadata"
use_managed_identity = true
----

== 3. API Usage

=== 3.1 Collection Management

==== Create Collection
[source,bash]
----
curl -X POST http://localhost:5678/collections \
  -H "Content-Type: application/json" \
  -d '{
    "name": "my_vectors",
    "dimension": 768,
    "distance_metric": "cosine"
  }'
----

==== List Collections
[source,bash]
----
curl -X GET http://localhost:5678/collections
----

==== Get Collection by Name or UUID
[source,bash]
----
# By name
curl -X GET http://localhost:5678/collections/my_vectors

# By UUID
curl -X GET http://localhost:5678/collections/550e8400-e29b-41d4-a716-446655440000
----

=== 3.2 Vector Operations

==== Insert Single Vector
[source,bash]
----
curl -X POST http://localhost:5678/collections/my_vectors/vectors \
  -H "Content-Type: application/json" \
  -d '{
    "id": "doc1",
    "vector": [0.1, 0.2, 0.3, 0.4],
    "metadata": {
      "title": "Document 1",
      "category": "tech"
    }
  }'
----

==== Batch Insert Vectors
[source,bash]
----
curl -X POST http://localhost:5678/collections/my_vectors/vectors/batch \
  -H "Content-Type: application/json" \
  -d '{
    "vectors": [
      {
        "id": "doc1",
        "vector": [0.1, 0.2, 0.3, 0.4],
        "metadata": {"title": "Document 1"}
      },
      {
        "id": "doc2", 
        "vector": [0.4, 0.5, 0.6, 0.7],
        "metadata": {"title": "Document 2"}
      }
    ]
  }'
----

==== Search Vectors
[source,bash]
----
curl -X POST http://localhost:5678/collections/my_vectors/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": [0.1, 0.2, 0.3, 0.4],
    "k": 10,
    "filter": {
      "category": "tech"
    }
  }'
----

=== 3.3 Python SDK

==== Installation
[source,bash]
----
pip install proximadb
----

==== Basic Usage
[source,python]
----
from proximadb import ProximaDBClient

# Create client (auto-detects protocol based on port)
client = ProximaDBClient("localhost:5678")  # REST
# or
client = ProximaDBClient("localhost:5679")  # gRPC

# Collection operations
collection = client.create_collection(
    name="documents",
    dimension=384,
    distance_metric="cosine"
)

# Insert vectors
client.insert_vector(
    collection_id="documents",
    vector_id="doc1",
    vector=[0.1, 0.2, 0.3] * 128,  # 384 dimensions
    metadata={"title": "Sample Document", "category": "tech"}
)

# Search
results = client.search(
    collection_id="documents",
    query_vector=[0.1, 0.2, 0.3] * 128,
    k=10,
    filter={"category": "tech"}
)
----

== 4. Working with Embeddings

=== 4.1 BERT Embeddings

[source,python]
----
from sentence_transformers import SentenceTransformer
from proximadb import ProximaDBClient

# Load model
model = SentenceTransformer('all-MiniLM-L6-v2')  # 384 dimensions

# Create client and collection
client = ProximaDBClient("localhost:5678")
collection = client.create_collection(
    name="text_embeddings",
    dimension=384,
    distance_metric="cosine"
)

# Generate embeddings and insert
texts = [
    "The quick brown fox jumps over the lazy dog",
    "Machine learning is a subset of artificial intelligence",
    "Vector databases store high-dimensional data efficiently"
]

for i, text in enumerate(texts):
    embedding = model.encode(text).tolist()
    client.insert_vector(
        collection_id="text_embeddings",
        vector_id=f"text_{i}",
        vector=embedding,
        metadata={"text": text, "source": "example"}
    )

# Search for similar text
query = "What is machine learning?"
query_embedding = model.encode(query).tolist()

results = client.search(
    collection_id="text_embeddings",
    query_vector=query_embedding,
    k=3
)

for result in results:
    print(f"Score: {result['score']:.4f}")
    print(f"Text: {result['metadata']['text']}")
    print("---")
----

== 5. Multi-Disk Assignment Service

=== 5.1 Understanding Assignment

ProximaDB automatically assigns collections to disks using the assignment service:

* **Round-Robin Distribution**: Collections are evenly distributed across configured disks
* **Collection Affinity**: Collections can be assigned to specific disks consistently
* **Discovery-Based Recovery**: Assignments are discovered during startup by scanning directories

=== 5.2 Monitoring Assignment Service

==== Check Assignment Statistics
[source,bash]
----
curl http://localhost:5678/admin/assignment/stats
----

Example response:
[source,json]
----
{
  "wal": {
    "total_assignments": 15,
    "directory_distribution": {
      "0": 5,
      "1": 5,
      "2": 5
    },
    "assignment_strategy": "LoadBalanced"
  },
  "storage": {
    "total_assignments": 15,
    "directory_distribution": {
      "0": 5,
      "1": 5,
      "2": 5
    }
  }
}
----

==== Check Storage Usage
[source,bash]
----
curl http://localhost:5678/admin/storage/usage
----

=== 5.3 Assignment Strategies

==== LoadBalanced (Default)
Collections are assigned to disks in round-robin fashion for even distribution.

==== HashBased
Collections are assigned based on hash of collection ID for consistent placement.

==== PerformanceBased
Collections are assigned to fastest available disk based on disk performance characteristics.

== 6. Performance Optimization

=== 6.1 Multi-Disk Setup for High Performance

[source,toml]
----
[storage.wal_config]
wal_urls = [
    "file:///mnt/nvme1/proximadb/wal",
    "file:///mnt/nvme2/proximadb/wal",
    "file:///mnt/nvme3/proximadb/wal",
    "file:///mnt/nvme4/proximadb/wal"
]
distribution_strategy = "PerformanceBased"
collection_affinity = true
memory_flush_size_bytes = 16777216  # 16MB for high throughput
global_flush_threshold = 1073741824  # 1GB
----

=== 6.2 Memory Tuning

Adjust memory settings based on workload:

[source,toml]
----
[storage.wal_config]
# High-throughput workloads
memory_flush_size_bytes = 67108864    # 64MB
global_flush_threshold = 2147483648   # 2GB

# Low-latency workloads  
memory_flush_size_bytes = 1048576     # 1MB
global_flush_threshold = 536870912    # 512MB
----

=== 6.3 Disk Performance Configuration

[source,toml]
----
[[storage.storage_layout.base_paths]]
base_dir = "/mnt/nvme1/storage"
disk_type = { NvmeSsd = { max_iops = 500000 } }
capacity_config = { 
    max_wal_size_mb = 10240,
    metadata_reserved_mb = 1024,
    warning_threshold_percent = 90.0 
}
----

== 7. Monitoring and Maintenance

=== 7.1 Health Monitoring

[source,bash]
----
# Basic health check
curl http://localhost:5678/health

# Assignment service health
curl http://localhost:5678/health/assignment

# Detailed system metrics
curl http://localhost:5678/admin/metrics
----

=== 7.2 Log Monitoring

[source,bash]
----
# Monitor assignment operations
tail -f /var/log/proximadb/server.log | grep "assignment"

# Monitor round-robin distribution
tail -f /var/log/proximadb/server.log | grep "round-robin"

# Monitor WAL operations
tail -f /var/log/proximadb/server.log | grep "WAL\|flush"

# Monitor multi-disk operations
tail -f /var/log/proximadb/server.log | grep "multi-disk"
----

=== 7.3 Disk Space Monitoring

[source,bash]
----
# Check all configured disk usage
for disk in /data/disk1 /data/disk2 /data/disk3; do
    echo "=== $disk ==="
    df -h $disk
    du -sh $disk/wal $disk/storage $disk/metadata 2>/dev/null
done

# Monitor disk performance
iostat -x 1
----

== 8. Backup and Recovery

=== 8.1 Multi-Disk Backup Strategy

[source,bash]
----
# Create consistent backup across all disks
#!/bin/bash
BACKUP_DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backup/proximadb-${BACKUP_DATE}"

# Stop ProximaDB
systemctl stop proximadb

# Backup all disk directories
mkdir -p ${BACKUP_DIR}
for disk in /data/disk1 /data/disk2 /data/disk3; do
    if [ -d "$disk" ]; then
        echo "Backing up $disk..."
        cp -r $disk ${BACKUP_DIR}/$(basename $disk)
    fi
done

# Create backup manifest
cat > ${BACKUP_DIR}/backup_info.json <<EOF
{
  "backup_date": "${BACKUP_DATE}",
  "disks_backed_up": ["/data/disk1", "/data/disk2", "/data/disk3"],
  "assignment_service": "enabled",
  "distribution_strategy": "LoadBalanced"
}
EOF

# Restart ProximaDB
systemctl start proximadb

echo "Backup completed: ${BACKUP_DIR}"
----

=== 8.2 Recovery Process

ProximaDB automatically recovers assignments and data:

1. **Assignment Discovery**: Scans all configured directories for collections
2. **Assignment Reconstruction**: Rebuilds assignment mappings
3. **WAL Recovery**: Replays write-ahead logs from all disks
4. **Data Verification**: Ensures data consistency across disks

Manual recovery verification:
[source,bash]
----
# Check assignment recovery
curl http://localhost:5678/admin/assignment/stats

# Verify collection recovery
curl http://localhost:5678/collections

# Check WAL recovery logs
grep "assignment\|recovery" /var/log/proximadb/server.log
----

== 9. Troubleshooting

=== 9.1 Assignment Service Issues

==== Poor Distribution
[source,bash]
----
# Check current distribution
curl http://localhost:5678/admin/assignment/stats | jq '.wal.directory_distribution'

# Expected even distribution: {"0": 5, "1": 4, "2": 4}
# Poor distribution: {"0": 13, "1": 0, "2": 0}
----

Solution: Restart server to trigger redistribution or check disk accessibility.

==== Assignment Service Not Working
[source,bash]
----
# Check assignment service initialization
grep "RoundRobinAssignmentService" /var/log/proximadb/server.log

# Verify directory permissions
ls -la /data/disk*/wal /data/disk*/storage

# Test directory creation
sudo -u proximadb mkdir -p /data/disk1/wal/test_collection
----

=== 9.2 Configuration Issues

==== Invalid WAL URLs
[source,bash]
----
# Common URL format errors:
# ❌ Incorrect: file://data/disk1/wal (missing slash)
# ✅ Correct: file:///data/disk1/wal

# Check configuration syntax
proximadb-server --config config.toml --check-config
----

==== Disk Space Issues
[source,bash]
----
# Check disk space on all configured drives
df -h /data/disk1 /data/disk2 /data/disk3

# Check ProximaDB disk usage warnings
grep "warning_threshold\|disk.*full" /var/log/proximadb/server.log
----

=== 9.3 Performance Issues

==== High Memory Usage
Adjust flush thresholds:
[source,toml]
----
[storage.wal_config]
memory_flush_size_bytes = 1048576     # Reduce to 1MB
global_flush_threshold = 268435456    # Reduce to 256MB
----

==== Slow Assignment Operations
Check disk I/O performance:
[source,bash]
----
# Monitor disk I/O
iostat -x 1

# Check for disk bottlenecks
iotop -o
----

== Conclusion

ProximaDB's multi-disk assignment service provides enterprise-grade performance, reliability, and scalability. The intelligent distribution across multiple disks ensures optimal resource utilization and fault tolerance while maintaining data consistency and fast recovery capabilities.

For additional support, consult the comprehensive documentation or engage with the ProximaDB community.